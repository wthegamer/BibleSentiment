{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "27c04fab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>abased</th>\n",
       "      <th>abasedand</th>\n",
       "      <th>abba</th>\n",
       "      <th>abel</th>\n",
       "      <th>abelto</th>\n",
       "      <th>abia</th>\n",
       "      <th>abide</th>\n",
       "      <th>abidein</th>\n",
       "      <th>abideth</th>\n",
       "      <th>abidethere</th>\n",
       "      <th>...</th>\n",
       "      <th>youyou</th>\n",
       "      <th>zabulon</th>\n",
       "      <th>zacchaeus</th>\n",
       "      <th>zacchaeuswanted</th>\n",
       "      <th>zacharias</th>\n",
       "      <th>zeal</th>\n",
       "      <th>zebedee</th>\n",
       "      <th>zebedees</th>\n",
       "      <th>zelotes</th>\n",
       "      <th>zorobabel</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>John</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Luke</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Mark</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Matthew</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4 rows Ã— 7071 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         abased  abasedand  abba  abel  abelto  abia  abide  abidein  abideth  \\\n",
       "John          0          0     0     0       0     0      9        1        4   \n",
       "Luke          2          0     0     1       0     1      2        0        0   \n",
       "Mark          0          0     1     0       0     0      0        0        0   \n",
       "Matthew       0          1     0     0       1     0      1        0        0   \n",
       "\n",
       "         abidethere  ...  youyou  zabulon  zacchaeus  zacchaeuswanted  \\\n",
       "John              0  ...       0        0          0                0   \n",
       "Luke              0  ...       1        0          3                1   \n",
       "Mark              1  ...       0        0          0                0   \n",
       "Matthew           0  ...       0        1          0                0   \n",
       "\n",
       "         zacharias  zeal  zebedee  zebedees  zelotes  zorobabel  \n",
       "John             0     1        0         0        0          0  \n",
       "Luke             8     0        0         0        1          1  \n",
       "Mark             0     0        3         0        0          0  \n",
       "Matthew          1     0        3         1        0          0  \n",
       "\n",
       "[4 rows x 7071 columns]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# read in the matrix\n",
    "import pandas as pd\n",
    "import pickle\n",
    "\n",
    "data = pd.read_pickle('dtm_stop.pkl')\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "b55d3f4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the necessary modules for LDA with gensim\n",
    "# Terminal / Anaconda Navigator: conda install -c conda-forge gensim\n",
    "from gensim import matutils, models\n",
    "import scipy.sparse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "c8acfd60",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>John</th>\n",
       "      <th>Luke</th>\n",
       "      <th>Mark</th>\n",
       "      <th>Matthew</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>abased</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>abasedand</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>abba</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>abel</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>abelto</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           John  Luke  Mark  Matthew\n",
       "abased        0     2     0        0\n",
       "abasedand     0     0     0        1\n",
       "abba          0     0     1        0\n",
       "abel          0     1     0        0\n",
       "abelto        0     0     0        1"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# One of the required inputs is a term-document matrix\n",
    "tdm = data.transpose()\n",
    "tdm.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "57a9cceb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We're going to put the term-document matrix into a new gensim format, from df --> sparse matrix --> gensim corpus\n",
    "sparse_counts = scipy.sparse.csr_matrix(tdm)\n",
    "corpus = matutils.Sparse2Corpus(sparse_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "00842594",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gensim also requires dictionary of the all terms and their respective location in the term-document matrix\n",
    "cv = pickle.load(open(\"cv_stop.pkl\", \"rb\"))\n",
    "id2word = dict((v, k) for k, v in cv.vocabulary_.items())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "e5f3498e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0,\n",
       "  '0.005*\"people\" + 0.005*\"house\" + 0.004*\"day\" + 0.004*\"away\" + 0.004*\"let\" + 0.003*\"john\" + 0.003*\"saying\" + 0.003*\"took\" + 0.003*\"heard\" + 0.003*\"cast\"'),\n",
       " (1,\n",
       "  '0.019*\"unto\" + 0.006*\"saith\" + 0.005*\"know\" + 0.005*\"world\" + 0.005*\"answered\" + 0.005*\"heaven\" + 0.004*\"sent\" + 0.004*\"did\" + 0.004*\"day\" + 0.004*\"jews\"')]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Now that we have the corpus (term-document matrix) and id2word (dictionary of location: term),\n",
    "# we need to specify two other parameters as well - the number of topics and the number of passes\n",
    "lda = models.LdaModel(corpus=corpus, id2word=id2word, num_topics=2, passes=10)\n",
    "lda.print_topics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "c7080772",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0,\n",
       "  '0.032*\"unto\" + 0.011*\"saith\" + 0.009*\"world\" + 0.009*\"know\" + 0.008*\"answered\" + 0.007*\"hath\" + 0.007*\"jews\" + 0.006*\"sent\" + 0.005*\"believe\" + 0.005*\"verily\"'),\n",
       " (1,\n",
       "  '0.000*\"unto\" + 0.000*\"people\" + 0.000*\"know\" + 0.000*\"let\" + 0.000*\"men\" + 0.000*\"away\" + 0.000*\"day\" + 0.000*\"house\" + 0.000*\"sent\" + 0.000*\"took\"'),\n",
       " (2,\n",
       "  '0.005*\"people\" + 0.004*\"day\" + 0.004*\"house\" + 0.004*\"took\" + 0.004*\"away\" + 0.004*\"heaven\" + 0.004*\"cast\" + 0.004*\"let\" + 0.004*\"did\" + 0.004*\"men\"')]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# LDA for num_topics = 3\n",
    "lda = models.LdaModel(corpus=corpus, id2word=id2word, num_topics=3, passes=10)\n",
    "lda.print_topics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "b8885cd7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0,\n",
       "  '0.001*\"unto\" + 0.000*\"people\" + 0.000*\"day\" + 0.000*\"sent\" + 0.000*\"took\" + 0.000*\"answered\" + 0.000*\"john\" + 0.000*\"house\" + 0.000*\"know\" + 0.000*\"heard\"'),\n",
       " (1,\n",
       "  '0.005*\"took\" + 0.005*\"heaven\" + 0.005*\"away\" + 0.004*\"cast\" + 0.004*\"unto\" + 0.004*\"did\" + 0.004*\"people\" + 0.004*\"men\" + 0.004*\"heard\" + 0.004*\"let\"'),\n",
       " (2,\n",
       "  '0.005*\"house\" + 0.005*\"people\" + 0.005*\"day\" + 0.004*\"saying\" + 0.004*\"great\" + 0.003*\"let\" + 0.003*\"tell\" + 0.003*\"good\" + 0.003*\"called\" + 0.003*\"city\"'),\n",
       " (3,\n",
       "  '0.035*\"unto\" + 0.012*\"saith\" + 0.010*\"world\" + 0.009*\"know\" + 0.008*\"answered\" + 0.008*\"hath\" + 0.007*\"jews\" + 0.007*\"sent\" + 0.006*\"believe\" + 0.005*\"verily\"')]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# LDA for num_topics = 4\n",
    "lda = models.LdaModel(corpus=corpus, id2word=id2word, num_topics=4, passes=10)\n",
    "lda.print_topics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "65761ce2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# These topics could be better. Is unto a topic? no\n",
    "# Let's create a function to pull out nouns from a string of text\n",
    "from nltk import word_tokenize, pos_tag\n",
    "\n",
    "def nouns(text):\n",
    "    '''Given a string of text, tokenize the text and pull out only the nouns.'''\n",
    "    is_noun = lambda pos: pos[:2] == 'NN'\n",
    "    tokenized = word_tokenize(text)\n",
    "    all_nouns = [word for (word, pos) in pos_tag(tokenized) if is_noun(pos)] \n",
    "    return ' '.join(all_nouns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "05abd086",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>transcripts</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>John</th>\n",
       "      <td>title the gospel of john for readers editor li...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Luke</th>\n",
       "      <td>title the gospel of luke for readers editor li...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Mark</th>\n",
       "      <td>title the gospel of mark for readers editor li...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Matthew</th>\n",
       "      <td>title the gospel of matthew for readers editor...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               transcripts\n",
       "John     title the gospel of john for readers editor li...\n",
       "Luke     title the gospel of luke for readers editor li...\n",
       "Mark     title the gospel of mark for readers editor li...\n",
       "Matthew  title the gospel of matthew for readers editor..."
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read in the cleaned data, before the CountVectorizer step\n",
    "data_clean = pd.read_pickle('data_clean.pkl')\n",
    "data_clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "fd54a1a2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>transcripts</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>John</th>\n",
       "      <td>gospel john readers editor lightheart release ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Luke</th>\n",
       "      <td>gospel luke readers editor lightheart release ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Mark</th>\n",
       "      <td>gospel mark readers editor lightheart release ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Matthew</th>\n",
       "      <td>gospel matthew readers editor lightheart relea...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               transcripts\n",
       "John     gospel john readers editor lightheart release ...\n",
       "Luke     gospel luke readers editor lightheart release ...\n",
       "Mark     gospel mark readers editor lightheart release ...\n",
       "Matthew  gospel matthew readers editor lightheart relea..."
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Apply the nouns function to the transcripts to filter only on nouns\n",
    "data_nouns = pd.DataFrame(data_clean.transcripts.apply(nouns))\n",
    "data_nouns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "42fdfc06",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>abel</th>\n",
       "      <th>abide</th>\n",
       "      <th>abideth</th>\n",
       "      <th>abilene</th>\n",
       "      <th>ability</th>\n",
       "      <th>aboat</th>\n",
       "      <th>abode</th>\n",
       "      <th>abomination</th>\n",
       "      <th>aboutgalilee</th>\n",
       "      <th>aboutthee</th>\n",
       "      <th>...</th>\n",
       "      <th>youth</th>\n",
       "      <th>youyou</th>\n",
       "      <th>zabulon</th>\n",
       "      <th>zacchaeus</th>\n",
       "      <th>zacharias</th>\n",
       "      <th>zeal</th>\n",
       "      <th>zebedee</th>\n",
       "      <th>zebedees</th>\n",
       "      <th>zelotes</th>\n",
       "      <th>zorobabel</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>John</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Luke</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Mark</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Matthew</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4 rows Ã— 3620 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         abel  abide  abideth  abilene  ability  aboat  abode  abomination  \\\n",
       "John        0      3        2        0        0      0      2            0   \n",
       "Luke        1      1        0        1        0      0      1            0   \n",
       "Mark        0      0        0        0        0      1      0            1   \n",
       "Matthew     0      0        0        0        1      0      0            0   \n",
       "\n",
       "         aboutgalilee  aboutthee  ...  youth  youyou  zabulon  zacchaeus  \\\n",
       "John                0          0  ...      0       0        0          0   \n",
       "Luke                0          1  ...      1       1        0          2   \n",
       "Mark                0          0  ...      0       0        0          0   \n",
       "Matthew             1          0  ...      1       0        1          0   \n",
       "\n",
       "         zacharias  zeal  zebedee  zebedees  zelotes  zorobabel  \n",
       "John             0     1        0         0        0          0  \n",
       "Luke             8     0        0         0        1          1  \n",
       "Mark             0     0        3         0        0          0  \n",
       "Matthew          1     0        3         1        0          0  \n",
       "\n",
       "[4 rows x 3620 columns]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a new document-term matrix using only nouns\n",
    "from sklearn.feature_extraction import text\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "# Re-add the additional stop words since we are recreating the document-term matrix\n",
    "add_stop_words = ['andif','himand','like', 'im', 'know', 'just', 'dont', 'thats', 'right', 'people',\n",
    "                  'youre', 'got', 'gonna', 'time', 'think', 'yeah', 'said', 'unto', 'saith', 'hath', 'thou', 'ye', 'thee', 'hast', 'shalt',\n",
    "                 'sayest', 'cometh', 'woe']\n",
    "stop_words = text.ENGLISH_STOP_WORDS.union(add_stop_words)\n",
    "\n",
    "# Recreate a document-term matrix with only nouns\n",
    "cvn = CountVectorizer(stop_words=list(stop_words))\n",
    "data_cvn = cvn.fit_transform(data_nouns.transcripts)\n",
    "data_dtmn = pd.DataFrame(data_cvn.toarray(), columns=cvn.get_feature_names_out())\n",
    "data_dtmn.index = data_nouns.index\n",
    "data_dtmn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "d38eed99",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the gensim corpus\n",
    "corpusn = matutils.Sparse2Corpus(scipy.sparse.csr_matrix(data_dtmn.transpose()))\n",
    "\n",
    "# Create the vocabulary dictionary\n",
    "id2wordn = dict((v, k) for k, v in cvn.vocabulary_.items())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "72c32659",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0,\n",
       "  '0.002*\"jesus\" + 0.001*\"son\" + 0.001*\"man\" + 0.001*\"god\" + 0.001*\"things\" + 0.001*\"father\" + 0.001*\"disciples\" + 0.001*\"day\" + 0.001*\"lord\" + 0.001*\"world\"'),\n",
       " (1,\n",
       "  '0.048*\"jesus\" + 0.027*\"man\" + 0.019*\"son\" + 0.014*\"god\" + 0.013*\"things\" + 0.012*\"father\" + 0.011*\"disciples\" + 0.011*\"lord\" + 0.008*\"day\" + 0.007*\"kingdom\"')]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's start with 2 topics\n",
    "ldan = models.LdaModel(corpus=corpusn, num_topics=2, id2word=id2wordn, passes=10)\n",
    "ldan.print_topics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "671d1aae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0,\n",
       "  '0.050*\"jesus\" + 0.028*\"man\" + 0.020*\"son\" + 0.015*\"god\" + 0.014*\"things\" + 0.013*\"father\" + 0.012*\"disciples\" + 0.012*\"lord\" + 0.008*\"day\" + 0.007*\"kingdom\"'),\n",
       " (1,\n",
       "  '0.002*\"jesus\" + 0.001*\"man\" + 0.001*\"son\" + 0.001*\"god\" + 0.001*\"disciples\" + 0.001*\"lord\" + 0.001*\"father\" + 0.001*\"things\" + 0.000*\"men\" + 0.000*\"house\"'),\n",
       " (2,\n",
       "  '0.002*\"jesus\" + 0.001*\"son\" + 0.001*\"man\" + 0.001*\"god\" + 0.001*\"lord\" + 0.001*\"things\" + 0.001*\"day\" + 0.001*\"father\" + 0.001*\"house\" + 0.000*\"disciples\"')]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# looking better\n",
    "# Let's try topics = 3\n",
    "ldan = models.LdaModel(corpus=corpusn, num_topics=3, id2word=id2wordn, passes=10)\n",
    "ldan.print_topics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "5319b022",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0,\n",
       "  '0.001*\"jesus\" + 0.001*\"man\" + 0.001*\"son\" + 0.001*\"god\" + 0.001*\"things\" + 0.001*\"disciples\" + 0.001*\"lord\" + 0.001*\"father\" + 0.000*\"day\" + 0.000*\"house\"'),\n",
       " (1,\n",
       "  '0.041*\"jesus\" + 0.025*\"man\" + 0.022*\"son\" + 0.014*\"lord\" + 0.014*\"god\" + 0.013*\"things\" + 0.009*\"disciples\" + 0.009*\"kingdom\" + 0.009*\"day\" + 0.008*\"father\"'),\n",
       " (2,\n",
       "  '0.051*\"jesus\" + 0.026*\"man\" + 0.025*\"father\" + 0.018*\"world\" + 0.015*\"son\" + 0.015*\"god\" + 0.014*\"things\" + 0.014*\"jews\" + 0.012*\"disciples\" + 0.009*\"life\"'),\n",
       " (3,\n",
       "  '0.052*\"jesus\" + 0.028*\"man\" + 0.012*\"disciples\" + 0.011*\"son\" + 0.010*\"things\" + 0.010*\"god\" + 0.006*\"house\" + 0.006*\"hand\" + 0.006*\"kingdom\" + 0.006*\"way\"')]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's try 4 topics\n",
    "ldan = models.LdaModel(corpus=corpusn, num_topics=4, id2word=id2wordn, passes=10)\n",
    "ldan.print_topics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "b52c6ffa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's create a function to pull out nouns and adjectives from a string of text\n",
    "def nouns_adj(text):\n",
    "    '''Given a string of text, tokenize the text and pull out only the nouns and adjectives.'''\n",
    "    is_noun_adj = lambda pos: pos[:2] == 'NN' or pos[:2] == 'JJ'\n",
    "    tokenized = word_tokenize(text)\n",
    "    nouns_adj = [word for (word, pos) in pos_tag(tokenized) if is_noun_adj(pos)] \n",
    "    return ' '.join(nouns_adj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "de2a8f73",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>transcripts</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>John</th>\n",
       "      <td>gospel john readers editor lightheart release ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Luke</th>\n",
       "      <td>gospel luke readers editor lightheart release ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Mark</th>\n",
       "      <td>gospel mark readers editor lightheart release ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Matthew</th>\n",
       "      <td>gospel matthew readers editor lightheart relea...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               transcripts\n",
       "John     gospel john readers editor lightheart release ...\n",
       "Luke     gospel luke readers editor lightheart release ...\n",
       "Mark     gospel mark readers editor lightheart release ...\n",
       "Matthew  gospel matthew readers editor lightheart relea..."
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Apply the nouns function to the transcripts to filter only on nouns and adjectives\n",
    "data_nouns_adj = pd.DataFrame(data_clean.transcripts.apply(nouns_adj))\n",
    "data_nouns_adj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "463b9ea8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>abel</th>\n",
       "      <th>abia</th>\n",
       "      <th>abide</th>\n",
       "      <th>abideth</th>\n",
       "      <th>abilene</th>\n",
       "      <th>ability</th>\n",
       "      <th>able</th>\n",
       "      <th>ableto</th>\n",
       "      <th>aboat</th>\n",
       "      <th>abode</th>\n",
       "      <th>...</th>\n",
       "      <th>youwill</th>\n",
       "      <th>youyou</th>\n",
       "      <th>zabulon</th>\n",
       "      <th>zacchaeus</th>\n",
       "      <th>zacharias</th>\n",
       "      <th>zeal</th>\n",
       "      <th>zebedee</th>\n",
       "      <th>zebedees</th>\n",
       "      <th>zelotes</th>\n",
       "      <th>zorobabel</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>John</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Luke</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Mark</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Matthew</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4 rows Ã— 4148 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         abel  abia  abide  abideth  abilene  ability  able  ableto  aboat  \\\n",
       "John        0     0      3        2        0        0     1       1      0   \n",
       "Luke        1     1      1        0        1        0     6       0      0   \n",
       "Mark        0     0      0        0        0        0     0       0      1   \n",
       "Matthew     0     0      0        0        0        1     9       0      0   \n",
       "\n",
       "         abode  ...  youwill  youyou  zabulon  zacchaeus  zacharias  zeal  \\\n",
       "John         2  ...        0       0        0          0          0     1   \n",
       "Luke         1  ...        1       1        0          2          8     0   \n",
       "Mark         0  ...        0       0        0          0          0     0   \n",
       "Matthew      0  ...        0       0        1          0          1     0   \n",
       "\n",
       "         zebedee  zebedees  zelotes  zorobabel  \n",
       "John           0         0        0          0  \n",
       "Luke           0         0        1          1  \n",
       "Mark           3         0        0          0  \n",
       "Matthew        3         1        0          0  \n",
       "\n",
       "[4 rows x 4148 columns]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a new document-term matrix using only nouns and adjectives, also remove common words with max_df\n",
    "cvna = CountVectorizer(stop_words=list(stop_words), max_df=.8)\n",
    "data_cvna = cvna.fit_transform(data_nouns_adj.transcripts)\n",
    "data_dtmna = pd.DataFrame(data_cvna.toarray(), columns=cvna.get_feature_names_out())\n",
    "data_dtmna.index = data_nouns_adj.index\n",
    "data_dtmna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "d8d54913",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the gensim corpus\n",
    "corpusna = matutils.Sparse2Corpus(scipy.sparse.csr_matrix(data_dtmna.transpose()))\n",
    "\n",
    "# Create the vocabulary dictionary\n",
    "id2wordna = dict((v, k) for k, v in cvna.vocabulary_.items())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "59899858",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0,\n",
       "  '0.005*\"light\" + 0.004*\"law\" + 0.003*\"devils\" + 0.003*\"eye\" + 0.003*\"angel\" + 0.002*\"generation\" + 0.002*\"disciple\" + 0.002*\"faith\" + 0.002*\"works\" + 0.002*\"worthy\"'),\n",
       " (1,\n",
       "  '0.003*\"james\" + 0.002*\"devils\" + 0.002*\"herod\" + 0.002*\"unclean\" + 0.002*\"elders\" + 0.002*\"cast\" + 0.002*\"damsel\" + 0.002*\"soul\" + 0.002*\"false\" + 0.002*\"heed\"')]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's start with 2 topics\n",
    "ldana = models.LdaModel(corpus=corpusna, num_topics=2, id2word=id2wordna, passes=10)\n",
    "ldana.print_topics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "bbfa6680",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0,\n",
       "  '0.004*\"eye\" + 0.003*\"field\" + 0.003*\"talents\" + 0.003*\"light\" + 0.003*\"devils\" + 0.003*\"faith\" + 0.003*\"elders\" + 0.003*\"generation\" + 0.003*\"hypocrites\" + 0.003*\"herod\"'),\n",
       " (1,\n",
       "  '0.003*\"james\" + 0.003*\"devils\" + 0.003*\"herod\" + 0.003*\"unclean\" + 0.003*\"elders\" + 0.002*\"cast\" + 0.002*\"damsel\" + 0.002*\"swine\" + 0.002*\"soul\" + 0.002*\"false\"'),\n",
       " (2,\n",
       "  '0.006*\"light\" + 0.005*\"law\" + 0.003*\"disciple\" + 0.003*\"fathers\" + 0.003*\"devils\" + 0.003*\"angel\" + 0.003*\"rich\" + 0.003*\"joy\" + 0.002*\"works\" + 0.002*\"judge\"')]"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's try 3 topics\n",
    "ldana = models.LdaModel(corpus=corpusna, num_topics=3, id2word=id2wordna, passes=10)\n",
    "ldana.print_topics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "0f893178",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0,\n",
       "  '0.004*\"james\" + 0.003*\"devils\" + 0.003*\"herod\" + 0.003*\"unclean\" + 0.003*\"elders\" + 0.003*\"cast\" + 0.003*\"damsel\" + 0.002*\"false\" + 0.002*\"soul\" + 0.002*\"heed\"'),\n",
       " (1,\n",
       "  '0.004*\"devils\" + 0.004*\"light\" + 0.004*\"eye\" + 0.004*\"generation\" + 0.003*\"angel\" + 0.003*\"faith\" + 0.003*\"herod\" + 0.003*\"rich\" + 0.003*\"worthy\" + 0.003*\"field\"'),\n",
       " (2,\n",
       "  '0.000*\"law\" + 0.000*\"light\" + 0.000*\"faith\" + 0.000*\"herod\" + 0.000*\"worthy\" + 0.000*\"devils\" + 0.000*\"rich\" + 0.000*\"judge\" + 0.000*\"joy\" + 0.000*\"disciple\"'),\n",
       " (3,\n",
       "  '0.008*\"light\" + 0.006*\"law\" + 0.006*\"disciple\" + 0.005*\"works\" + 0.005*\"sin\" + 0.004*\"fathers\" + 0.004*\"philip\" + 0.003*\"record\" + 0.003*\"miracles\" + 0.003*\"love\"')]"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's try 4 topics\n",
    "ldana = models.LdaModel(corpus=corpusna, num_topics=4, id2word=id2wordna, passes=10)\n",
    "ldana.print_topics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "79b529ee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0,\n",
       "  '0.004*\"eye\" + 0.004*\"field\" + 0.003*\"talents\" + 0.003*\"elders\" + 0.003*\"faith\" + 0.003*\"generation\" + 0.003*\"devils\" + 0.003*\"hypocrites\" + 0.003*\"light\" + 0.003*\"prison\"'),\n",
       " (1,\n",
       "  '0.000*\"light\" + 0.000*\"law\" + 0.000*\"works\" + 0.000*\"shepherd\" + 0.000*\"branch\" + 0.000*\"honour\" + 0.000*\"sponge\" + 0.000*\"deny\" + 0.000*\"marvellous\" + 0.000*\"tabernacles\"'),\n",
       " (2,\n",
       "  '0.005*\"devils\" + 0.004*\"rich\" + 0.004*\"herod\" + 0.003*\"james\" + 0.003*\"generation\" + 0.003*\"angel\" + 0.003*\"unclean\" + 0.003*\"faith\" + 0.002*\"cast\" + 0.002*\"women\"'),\n",
       " (3,\n",
       "  '0.008*\"light\" + 0.006*\"law\" + 0.006*\"disciple\" + 0.005*\"works\" + 0.005*\"sin\" + 0.004*\"fathers\" + 0.004*\"philip\" + 0.003*\"love\" + 0.003*\"record\" + 0.003*\"miracles\"')]"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Our final LDA model (for now)\n",
    "ldana = models.LdaModel(corpus=corpusna, num_topics=4, id2word=id2wordna, passes=80)\n",
    "ldana.print_topics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "ef4d944b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(3, 'John'), (2, 'Luke'), (2, 'Mark'), (0, 'Matthew')]"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's take a look at which topics each transcript contains\n",
    "corpus_transformed = ldana[corpusna]\n",
    "list(zip([a for [(a,b)] in corpus_transformed], data_dtmna.index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f78e8227",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
